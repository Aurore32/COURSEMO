\documentclass{article}

\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage{thmtools}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{geometry}
\usepackage{float}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{framed}
\usepackage[dvipsnames]{xcolor}
\usepackage{tcolorbox}
\usepackage{graphicx}
\usepackage[normalem]{ulem}
\usepackage{media9}
\usepackage{animate}

\colorlet{LightGray}{White!90!Periwinkle}
\colorlet{LightOrange}{Orange!15}
\colorlet{LightGreen}{Green!15}

\newcommand{\HRule}[1]{\rule{\linewidth}{#1}}

\declaretheoremstyle[name=Theorem,]{thmsty}
\declaretheorem[style=thmsty,numberwithin=section]{theorem}
\tcolorboxenvironment{theorem}{colback=LightGray}

\declaretheoremstyle[name=Proposition,]{prosty}
\declaretheorem[style=prosty,numberlike=theorem]{proposition}
\tcolorboxenvironment{proposition}{colback=LightOrange}

\declaretheoremstyle[name=Principle,]{prcpsty}
\declaretheorem[style=prcpsty,numberlike=theorem]{principle}
\tcolorboxenvironment{principle}{colback=LightGreen}

\declaretheoremstyle[name=Definition,]{defsty}
\declaretheorem[style=defsty,numberlike=theorem]{definition}
\tcolorboxenvironment{definition}{colback=ProcessBlue}

\declaretheoremstyle[name=Method,]{metsty}
\declaretheorem[style=metsty,numberlike=theorem]{method}
\tcolorboxenvironment{method}{colback=Goldenrod}

\declaretheoremstyle[name=Example,]{exmsty}
\declaretheorem[style=exmsty,numberlike=theorem]{example}
\tcolorboxenvironment{example}{colback=ProcessBlue}



\setstretch{1.2}
\geometry{
    textheight=9in,
    textwidth=5.5in,
    top=1in,
    headheight=12pt,
    headsep=25pt,
    footskip=30pt
}

% ------------------------------------------------------------------------------

\begin{document}

% ------------------------------------------------------------------------------
% Cover Page and ToC
% ------------------------------------------------------------------------------

\title{ \normalsize \textsc{}
		\\ [2.0cm]
		\HRule{1.5pt} \\
		\LARGE \textbf{\uppercase{Vectors and Matrices}
		\HRule{2.0pt} \\ [0.6cm] \LARGE{Preliminary Notes} \vspace*{10\baselineskip}}
		}
\date{}
\author{\textbf{Turbo Huang} \\ 
		June 2024 \\
		For Cambridge University}

\maketitle
\newpage

\tableofcontents
\newpage
\section{Complex numbers}
And so we begin! I suppose this is a better opportunity than any for me to share a profound foreword to the erudite, learned journey of mathematical enlightenment we are about to embark on with linear algebra - namely, to answer the question: why learn linear algebra at all? There are only three reasons. First, you're a massive sci-fi movie nerd and have accidentally stumbled upon the far-inferior version of the Matrix. Second, you're a massive basketball fan and received the worst surprise of your entire life when you searched "Jordan form" on YouTube in hopes of basketball enlightenment. Third, you're a massive German and have taken linear algebra for the sole purpose of pronouncing \it eigenvalue \normalfont "the German way". Either or, I'm glad you're here with me; after all, if you're destined to become a machine learning dev earning seven figures and sunbathing in a luxury yacht, then - in the eternal words of wisdom of r/animememes - "don't say you love the anime if you haven't read the manga".
\\ \\
(Of course, besides all these completely unhinged things I'm talking about, I suppose there's also a few nuggets of mathematical beauty to be found in these curious morsels we call vectors and matrices here and there.) \\ \\
Let's start with a return to form: complex numbers. In the realm of linear algebra specifically, complex numbers are important for two reasons. First, in the set of complex numbers $\mathbb{C}$, we can guarantee that a polynomial of degree $n$ will have $n$ roots by the Fundamental Theorem of Algebra; never again will we have to worry about equations like $\lambda^2 + 1 =0$ making us more confused than tasting a burger from Pizza Hut and finding it delicious. This becomes particularly relevant when we have to deal with these polynomials, which arise when we find the eigenvalues of a particular matrix - more on that later. \\ \\
\begin{definition}
    (Complex number). We define the imaginary unit $i$ as satisfying $i^2 = -1$; as such, we also define the set of complex numbers $\mathbb{C}$ to encompass all numbers of the form 
    \begin{equation*}
        z=a+bi
    \end{equation*}
    where $a$ and $b$ are real. We write $a = \text{Re}(z)$, $b=\text{Im}(z)$, and the complex conjugate $\bar{z}=a-bi$ (a theorem in algebra will demonstrate that if $z$ is a root of a polynomial, then $\bar{z}$ is too).
\end{definition}
But second of all - and much more thematically - while real numbers are \it one-dimensional, \normalfont all lying upon the same infinitely long number line, complex numbers are two-dimensional; it is useful to think of $z=a+bi$ as a vector in the \it complex plane, \normalfont  $\begin{bmatrix}
    a\\b
\end{bmatrix}$. The representation of complex numbers as vectors is done on an \it Argand plane\normalfont , analogous to the Cartesian plane but with the x-axis representing the real part of $z$ and the y-axis representing the imaginary part. \\ \\
What follows is a carousel of important results for complex numbers which are truly astounding in their mind-numbingness, not because of what they are but because we've seen them all before:
\begin{definition}
    (Modulus and argument). Define the modulus of $z=a+bi$ as $|z|=\sqrt{a^2+b^2}$; this is analogous to the length of its vector representation on the Argand plane. Define its argument as the angle its vector makes with the real axis: $\arg z = \tan^{-1}(\frac{b}{a})$. The modulus-argument pair $(r,\theta)$ can uniquely describe a complex number $z$, but each $z$ has infinitely many arguments $\theta+2k\pi$ (a full revolution, but not the French kind). We often take only the principal argument - $-\pi<\theta<\pi$.
\end{definition}
\begin{proposition}
    We have 
    \begin{equation*}
        z\bar{z}=a^2+b^2 = |z|^2
    \end{equation*}
    and
    \begin{equation*}
        z^{-1}=\frac{\bar{z}}{|z|^2}
    \end{equation*}
\end{proposition}
\begin{theorem}
    (Triangle inequality). For any two complex numbers $z_1$ and $z_2$, we have 
    \begin{equation*}
        |z_1+z_2|\leq |z_1|+|z_2|
    \end{equation*}
    which can be shown by the geometrical interpretation of the two complex numbers as vectors representing sides of a triangle.
\end{theorem}
\subsection{Complex exponentiation}
To extend exponentiation to complex numbers, we use the Taylor series definition of exponentiation:
\begin{definition}
    (Exponential function). Define
    \begin{equation*}
        e^z=\sum_{n=0}^{\infty}\frac{x^z}{z!}
    \end{equation*}
    which can be verified to satisfy the properties we expect from the exponential function, including $e^{a}e^{b}=e^{a+b}$. We assume that this sum converges for all complex numbers $z$.
\end{definition}
Similarly, we would like to extend the trigonometric functions to the complex realm, where a geometric definition fails due to the budding, unhinged insanity that underlines the words "an angle of $39+46\pi i$ degrees":
\begin{definition}
    (Complex sine and cosine). Define
    \begin{equation*}
        \sin z = \sum_{n=0}^{\infty} (-1)^{n}\frac{x^{2n+1}}{(2n+1)!} = x-\frac{x^3}{3!}+\frac{x^5}{5!}+...
    \end{equation*}
    and 
    \begin{equation*}
        \cos z = \sum_{n=0}^{\infty} (-1)^{n}\frac{x^{2n}}{(2n)!} = 1-\frac{x^2}{2!}+\frac{x^4}{4!}-...
    \end{equation*}
\end{definition}
From the two above results, we obtain a very important formula throughout all of math.
\begin{theorem}
    (Euler's formula). 
    \begin{equation*}
        e^{iz}=\cos z + i\sin z
    \end{equation*}
    It almost feels like I ought to be wearing a suit and tie before I even dare to think about these symbols. We also note that any complex number can thus be written in terms of a complex exponential, as its modulus-argument form $(r,\theta)$ suggests it can be written as 
    \begin{equation*}
        z=r(\cos \theta + i\sin \theta)=re^{i\theta}
    \end{equation*}
    which allows us to state that multiplication between two complex numbers $z_1=r_1e^{i\theta_1}$ and $z_2=r_2e^{i\theta_2}$ requires the multiplication of their moduli and addition of their arguments.
\end{theorem}
\subsection{Roots of unity}
\begin{definition}
    (Roots of unity). We refer to the complex roots of the equation $\omega^n=1$ as the \it nth roots of unity\normalfont ; as this is a polynomial of deg $n$, we have $n$ roots of unity, which can be completely described by 
    \begin{equation*}
        \omega=e^{\frac{2\pi ki}{n}},\ k=0,1,2,3,...,(n-1).
    \end{equation*}
    As a consequence of the above, we also have 
    \begin{equation*}
        \sum \omega = 1+e^{\frac{2\pi i}{n}} + e^{\frac{4\pi i}{n}} + ... + e^{\frac{2(n-1)\pi i}{n}} = 0
    \end{equation*}
    (You may have noticed that we've reached a critical mass of handwaving away statements without proof in this section. De Moivre is surely spinning in his grave. The reason why is because I can't be bothered to prove any of this stuff, so the proofs are left as an exercise to the reader.)
\end{definition}
\subsection{Complex logarithms}
\begin{definition}
    (Complex logarithms). Define the complex logarithm $\omega = \ln z$ as the number which satisfies $e^\omega = z$. If $z$ is a complex number $z=re^{i\theta}$, then we have $e^{\omega} = re^{i\theta}$ and thus $\ln \frac{1}{r} = i\theta - \omega$ and $\omega = \ln re^{i\theta} = i\theta +\ln r$. (I'm just now realizing we could've got here with $\ln ab = \ln a + \ln b$.)
\end{definition}
\begin{definition}
    (Complex powers). Define $z^\alpha$ for complex $z$ as $e^{\alpha\ln z}$ where we insist that the argument used for $z$ is $-\pi < \theta < \pi$, the principal argument.
\end{definition}
\begin{definition}
    (De Moivre's Theorem).
    \begin{equation*}
        \cos n\theta + i\sin n\theta =(\cos \theta + i\sin n\theta)^n.
    \end{equation*}
    This can be proven by induction; it is functionally identical to stating that $e^{ni\theta}=(e^{i\theta})^n$, which is obvious over the reals but not so obvious over complex numbers.
\end{definition}
\subsection{Lines and circles}
\subsubsection{Complex equation of a line}
The equation is not called "complex equation of a line" because it involves complex numbers, but because it is unnecessarily complex. Observe. What can we do if we want to find a line that goes through the point $x_0$ on the Argand diagram and is parallel to some complex number $\omega$? By what we know of vector equations for lines, we can write the line as $x = x_0 + \lambda \omega$ for some real scalar $\lambda$. If we rewrite this as $\frac{x-x_0}{\omega}=\lambda$ and take the conjugate of both sides, we obtain
\begin{equation*}
    \frac{\bar{x}-\bar{x_0}}{\bar{\omega}}=\bar{\lambda}=\lambda
\end{equation*}
as $\lambda$ is real. Thus the conjugate of this expression is equal to itself:
\begin{equation*}
    \frac{\bar{x}-\bar{x_0}}{\bar{\omega}}=\frac{x-x_0}{\omega}
\end{equation*}
which gives us the equation of a line parallel to $\omega$ and passing through $x_0$. 
\subsubsection{Complex equation of a circle}
A circle with center $x_0$ and radius $r$, in abstract terms, is simply a locus of points a distance $r$ away from the center $x_0$. (In less abstract terms, it can be referred to as "half a Venn diagram" or "the inferior donut".) This can be formulated as 
\begin{equation*}
    |x-x_0|=r
\end{equation*}
or, squaring both sides,
\begin{equation*}
    \begin{aligned}
        |x-x_0|^2&=r^2 \\
        (x-x_0)(\bar{x}-\bar{x_0})=r^2
    \end{aligned}
\end{equation*}
\section{Vectors}

\end{document}